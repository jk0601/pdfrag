"""
app.py - Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
====================================
ë¸Œë¼ìš°ì €ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ, ë¬¸ì„œ ê´€ë¦¬, RAG ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì›¹ UIì…ë‹ˆë‹¤.

[ì‹¤í–‰ ë°©ë²•]
  streamlit run app.py

[ì´ˆë³´ì ì•ˆë‚´]
- Streamlit: Python ì½”ë“œë§Œìœ¼ë¡œ ì›¹ ì•±ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
- st.session_state: í˜ì´ì§€ê°€ ìƒˆë¡œê³ ì¹¨ë˜ì–´ë„ ë°ì´í„°ë¥¼ ìœ ì§€í•˜ëŠ” ì €ì¥ì†Œ
- st.chat_message: ì±—ë´‡ UIë¥¼ ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì»´í¬ë„ŒíŠ¸
"""

import os
import json
import csv
import io
import tempfile

import streamlit as st

from config import Config
from pipeline import ingest_file, SUPPORTED_EXTENSIONS
from chatbot.chat import RAGChatbot
from database.supabase_client import SupabaseDB


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="PDF-RAG ë¬¸ì„œ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

if "chatbot" not in st.session_state:
    st.session_state.chatbot = None


def get_chatbot() -> RAGChatbot:
    """ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    if st.session_state.chatbot is None:
        st.session_state.chatbot = RAGChatbot()
    return st.session_state.chatbot


def check_config() -> list[str]:
    """ì„¤ì • ê²€ì¦ í›„ ì˜¤ë¥˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return Config.validate()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°”: ë„¤ë¹„ê²Œì´ì…˜ + ì„¤ì • ìƒíƒœ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.title("ğŸ“š PDF-RAG")
    st.caption("ë¬¸ì„œ ê¸°ë°˜ AI ì±—ë´‡")

    st.divider()

    page = st.radio(
        "ë©”ë‰´",
        ["ğŸ’¬ ì±—ë´‡", "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“‹ ë¬¸ì„œ ê´€ë¦¬", "ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°", "âš™ï¸ ì„¤ì •"],
        label_visibility="collapsed",
    )

    st.divider()

    # ì„¤ì • ìƒíƒœ í‘œì‹œ
    errors = check_config()
    if errors:
        st.error("âš ï¸ ì„¤ì • í•„ìš”")
        for err in errors:
            st.caption(f"â€¢ {err}")
        st.caption("âš™ï¸ ì„¤ì • í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”")
    else:
        st.success("âœ… ì„¤ì • ì™„ë£Œ")

    st.divider()
    st.caption("ì§€ì› í˜•ì‹: PDF, ì´ë¯¸ì§€, PPTX")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€: ì±—ë´‡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def page_chat():
    st.header("ğŸ’¬ ë¬¸ì„œ ê¸°ë°˜ AI ì±—ë´‡")
    st.caption("ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤")

    errors = check_config()
    if errors:
        st.warning("ë¨¼ì € âš™ï¸ ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
        return

    # DB ìƒíƒœ í‘œì‹œ
    try:
        db = SupabaseDB()
        docs = db.list_documents()
        total_chunks = db.count_chunks()
        if docs:
            doc_names = ", ".join(d["filename"] for d in docs[:5])
            extra = f" ì™¸ {len(docs) - 5}ê°œ" if len(docs) > 5 else ""
            st.info(f"ğŸ“š ë¡œë“œëœ ë¬¸ì„œ {len(docs)}ê°œ ({doc_names}{extra}) Â· ì´ {total_chunks}ê°œ ì²­í¬")
        else:
            st.warning("ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œì—ì„œ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
    except Exception:
        pass

    col1, col2 = st.columns([6, 1])
    with col2:
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.chat_messages = []
            chatbot = get_chatbot()
            chatbot.reset_history()
            st.rerun()

    # ì´ì „ ëŒ€í™” í‘œì‹œ
    for msg in st.session_state.chat_messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥
    if question := st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        st.session_state.chat_messages.append(
            {"role": "user", "content": question}
        )
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            chatbot = get_chatbot()
            response = st.write_stream(chatbot.stream_answer(question))

        st.session_state.chat_messages.append(
            {"role": "assistant", "content": response}
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€: íŒŒì¼ ì—…ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def page_upload():
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    st.caption("PDF, ì´ë¯¸ì§€, PPTX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë¶„ì„í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤")

    errors = check_config()
    if errors:
        st.warning("ë¨¼ì € âš™ï¸ ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
        return

    # íŒŒì¼ ì—…ë¡œë”
    uploaded_files = st.file_uploader(
        "íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”",
        type=["pdf", "png", "jpg", "jpeg", "gif", "bmp", "tiff", "webp", "pptx"],
        accept_multiple_files=True,
        help="ì§€ì› í˜•ì‹: PDF, PNG, JPG, JPEG, GIF, BMP, TIFF, WEBP, PPTX",
    )

    if not uploaded_files:
        # ì•ˆë‚´ ì¹´ë“œ
        st.info(
            "**ì‚¬ìš© ë°©ë²•**\n\n"
            "1. ìœ„ ì˜ì—­ì— íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤\n"
            "2. ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
            "3. ì•„ë˜ 'ì²˜ë¦¬ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ DBì— ì €ì¥í•©ë‹ˆë‹¤\n"
            "4. ì €ì¥ì´ ì™„ë£Œë˜ë©´ ğŸ’¬ ì±—ë´‡ì—ì„œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        return

    # ì—…ë¡œë“œëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
    st.subheader(f"ğŸ“ ì„ íƒëœ íŒŒì¼ ({len(uploaded_files)}ê°œ)")

    for f in uploaded_files:
        size_kb = f.size / 1024
        if size_kb > 1024:
            size_str = f"{size_kb / 1024:.1f} MB"
        else:
            size_str = f"{size_kb:.1f} KB"

        ext = os.path.splitext(f.name)[1].lower()
        icon = {"pdf": "ğŸ“„", "pptx": "ğŸ“Š"}.get(ext.lstrip("."), "ğŸ–¼ï¸")
        st.text(f"  {icon}  {f.name}  ({size_str})")

    st.divider()

    # ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        use_vision = st.checkbox(
            "ğŸ” OpenAI Visionìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„",
            value=False,
            help="ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ë” ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤ (API ë¹„ìš© ì¶”ê°€ ë°œìƒ)",
        )
    with col2:
        ocr_enabled = st.checkbox(
            "ğŸ“ OCR í™œì„±í™” (Tesseract)",
            value=True,
            help="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. Tesseract ì„¤ì¹˜ í•„ìš”",
        )

    st.divider()

    # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
    if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘ â€” DBì— ì €ì¥", type="primary", use_container_width=True):
        total = len(uploaded_files)
        success_count = 0
        fail_count = 0

        for idx, uploaded_file in enumerate(uploaded_files):
            st.divider()
            st.subheader(f"ì²˜ë¦¬ ì¤‘ ({idx + 1}/{total}): {uploaded_file.name}")

            progress_bar = st.progress(0)
            status_text = st.empty()

            def on_progress(percent: int, message: str):
                progress_bar.progress(percent)
                status_text.text(message)

            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì²˜ë¦¬
            suffix = os.path.splitext(uploaded_file.name)[1]
            with tempfile.NamedTemporaryFile(
                delete=False, suffix=suffix
            ) as tmp:
                tmp.write(uploaded_file.getbuffer())
                tmp_path = tmp.name

            try:
                result = ingest_file(
                    tmp_path,
                    ocr_enabled=ocr_enabled,
                    use_vision_api=use_vision,
                    on_progress=on_progress,
                )

                if "error" in result:
                    st.error(f"âŒ ì‹¤íŒ¨: {result['error']}")
                    fail_count += 1
                else:
                    st.success(
                        f"âœ… **{uploaded_file.name}** ì²˜ë¦¬ ì™„ë£Œ!  \n"
                        f"ë¬¸ì„œ ID: `{result['document_id']}` Â· "
                        f"ì²­í¬: {result['chunk_count']}ê°œ Â· "
                        f"í…ìŠ¤íŠ¸: {result.get('text_length', 0):,}ì"
                    )
                    success_count += 1
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                fail_count += 1
            finally:
                os.unlink(tmp_path)

        st.divider()
        if success_count > 0:
            st.balloons()
        st.info(
            f"**ì²˜ë¦¬ ì™„ë£Œ** â€” ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {fail_count}ê°œ  \n"
            f"ğŸ’¬ ì±—ë´‡ í˜ì´ì§€ì—ì„œ ì—…ë¡œë“œí•œ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!"
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€: ë¬¸ì„œ ê´€ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def page_documents():
    st.header("ğŸ“‹ ë¬¸ì„œ ê´€ë¦¬")
    st.caption("ì €ì¥ëœ ë¬¸ì„œë¥¼ ì¡°íšŒí•˜ê³  ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    errors = check_config()
    if errors:
        st.warning("ë¨¼ì € âš™ï¸ ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
        return

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    try:
        db = SupabaseDB()
        documents = db.list_documents()
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
        return

    if not documents:
        st.info(
            "ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.  \n"
            "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ ë³´ì„¸ìš”."
        )
        return

    st.write(f"ì´ **{len(documents)}ê°œ**ì˜ ë¬¸ì„œê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    for doc in documents:
        size = doc.get("file_size", 0)
        if size > 1_000_000:
            size_str = f"{size / 1_000_000:.1f} MB"
        elif size > 1_000:
            size_str = f"{size / 1_000:.1f} KB"
        else:
            size_str = f"{size} B"

        file_type = doc.get("file_type", "")
        icon = {"pdf": "ğŸ“„", "pptx": "ğŸ“Š", "image": "ğŸ–¼ï¸"}.get(file_type, "ğŸ“")
        created = doc.get("created_at", "")[:19].replace("T", " ")

        with st.container(border=True):
            col1, col2, col3, col4 = st.columns([5, 2, 1, 1])

            with col1:
                st.markdown(f"**{icon} {doc['filename']}**")
                chunk_count = db.count_chunks(doc["id"])
                st.caption(
                    f"ID: {doc['id']} Â· "
                    f"ì¢…ë¥˜: {file_type.upper()} Â· "
                    f"í¬ê¸°: {size_str} Â· "
                    f"í˜ì´ì§€: {doc.get('page_count', '-')} Â· "
                    f"ì²­í¬: {chunk_count}ê°œ"
                )

            with col2:
                st.caption(f"ğŸ“… {created}")

            with col3:
                if st.button("ğŸ”", key=f"diag_{doc['id']}", help="ì§„ë‹¨ ì •ë³´ ë³´ê¸°"):
                    st.session_state[f"show_diag_{doc['id']}"] = True

            with col4:
                if st.button("ğŸ—‘ï¸", key=f"del_{doc['id']}", help="ì´ ë¬¸ì„œ ì‚­ì œ"):
                    db.delete_document(doc["id"])
                    st.success(f"'{doc['filename']}' ì‚­ì œ ì™„ë£Œ!")
                    st.rerun()

            # ì§„ë‹¨ ì •ë³´ í‘œì‹œ
            if st.session_state.get(f"show_diag_{doc['id']}", False):
                with st.expander("ğŸ” ì§„ë‹¨ ì •ë³´", expanded=True):
                    emb_status = db.check_embeddings_exist(doc["id"])
                    st.write(
                        f"- ì „ì²´ ì²­í¬: **{emb_status['total_chunks']}ê°œ**\n"
                        f"- ì„ë² ë”© ìˆìŒ: **{emb_status['with_embedding']}ê°œ**\n"
                        f"- ì„ë² ë”© ì—†ìŒ: **{emb_status['without_embedding']}ê°œ**"
                    )

                    if emb_status["without_embedding"] > 0:
                        st.warning("âš ï¸ ì„ë² ë”©ì´ ì—†ëŠ” ì²­í¬ê°€ ìˆìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì‚­ì œ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

                    samples = db.get_chunk_sample(doc["id"], limit=3)
                    if samples:
                        st.write("**ì²­í¬ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):**")
                        for s in samples:
                            preview = s["content"][:200] + "..." if len(s["content"]) > 200 else s["content"]
                            st.text(f"[ì²­í¬ {s['chunk_index']}] {preview}")

                    if st.button("ë‹«ê¸°", key=f"close_diag_{doc['id']}"):
                        st.session_state[f"show_diag_{doc['id']}"] = False
                        st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€: ë°ì´í„° ë‚´ë³´ë‚´ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def page_export():
    st.header("ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
    st.caption("RAG ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ì— ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    errors = check_config()
    if errors:
        st.warning("ë¨¼ì € âš™ï¸ ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
        return

    try:
        db = SupabaseDB()
        documents = db.list_documents()
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
        return

    if not documents:
        st.info("ğŸ“­ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ë¬¸ì„œ ì„ íƒ ---
    st.subheader("1. ë‚´ë³´ë‚¼ ë¬¸ì„œ ì„ íƒ")

    doc_options = {"ğŸ“š ì „ì²´ ë¬¸ì„œ": None}
    for doc in documents:
        chunk_count = db.count_chunks(doc["id"])
        label = f"{doc['filename']} ({chunk_count}ì²­í¬)"
        doc_options[label] = doc["id"]

    selected_label = st.selectbox("ë¬¸ì„œ ì„ íƒ", list(doc_options.keys()))
    selected_doc_id = doc_options[selected_label]

    # --- ì˜µì…˜ ---
    st.subheader("2. ë‚´ë³´ë‚´ê¸° ì˜µì…˜")

    col1, col2 = st.columns(2)
    with col1:
        export_format = st.radio("íŒŒì¼ í˜•ì‹", ["CSV", "JSON", "SQL (INSERTë¬¸)"])
    with col2:
        include_embedding = st.checkbox(
            "ì„ë² ë”© ë²¡í„° í¬í•¨",
            value=False,
            help="ë²¡í„° DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë•Œ í•„ìš”. íŒŒì¼ ìš©ëŸ‰ì´ ë§¤ìš° ì»¤ì§‘ë‹ˆë‹¤.",
        )
        include_metadata = st.checkbox("ë©”íƒ€ë°ì´í„° í¼ì¹˜ê¸°", value=True,
            help="metadata JSONì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.")

    st.divider()

    # --- ë¯¸ë¦¬ë³´ê¸° ---
    st.subheader("3. ë¯¸ë¦¬ë³´ê¸°")

    chunks = db.export_chunks(document_id=selected_doc_id, include_embedding=include_embedding)

    if not chunks:
        st.warning("ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¯¸ë¦¬ë³´ê¸°ìš© ë°ì´í„° ê°€ê³µ
    preview_data = []
    for c in chunks[:5]:
        row = {
            "chunk_id": c["id"],
            "document_id": c["document_id"],
            "chunk_index": c["chunk_index"],
            "content": c["content"][:100] + "..." if len(c["content"]) > 100 else c["content"],
        }
        if include_metadata and c.get("metadata"):
            meta = c["metadata"] if isinstance(c["metadata"], dict) else {}
            row["filename"] = meta.get("filename", "")
            row["file_type"] = meta.get("file_type", "")
            row["page_number"] = meta.get("page_number", "")
        if include_embedding:
            emb = c.get("embedding")
            if emb:
                row["embedding"] = f"[{len(emb) if isinstance(emb, list) else '?'}ì°¨ì› ë²¡í„°]"
        preview_data.append(row)

    st.dataframe(preview_data, use_container_width=True)
    st.caption(f"ì´ {len(chunks)}ê°œ ì²­í¬ ì¤‘ ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°")

    st.divider()

    # --- ë‹¤ìš´ë¡œë“œ ---
    st.subheader("4. ë‹¤ìš´ë¡œë“œ")

    # ë‚´ë³´ë‚´ê¸°ìš© ì „ì²´ ë°ì´í„° ê°€ê³µ
    export_rows = []
    for c in chunks:
        row = {
            "chunk_id": c["id"],
            "document_id": c["document_id"],
            "chunk_index": c["chunk_index"],
            "content": c["content"],
        }
        if include_metadata and c.get("metadata"):
            meta = c["metadata"] if isinstance(c["metadata"], dict) else {}
            row["filename"] = meta.get("filename", "")
            row["file_type"] = meta.get("file_type", "")
            row["page_number"] = meta.get("page_number", "")
        else:
            row["metadata"] = json.dumps(c.get("metadata", {}), ensure_ascii=False)
        row["created_at"] = c.get("created_at", "")
        if include_embedding:
            emb = c.get("embedding")
            if isinstance(emb, list):
                row["embedding"] = json.dumps(emb)
            else:
                row["embedding"] = str(emb) if emb else ""
        export_rows.append(row)

    file_suffix = f"_{documents[0]['filename'].split('.')[0]}" if selected_doc_id else "_all"

    if export_format == "CSV":
        output = io.StringIO()
        if export_rows:
            writer = csv.DictWriter(output, fieldnames=export_rows[0].keys())
            writer.writeheader()
            writer.writerows(export_rows)
        csv_data = output.getvalue()

        st.download_button(
            label=f"â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ ({len(export_rows)}í–‰)",
            data=csv_data,
            file_name=f"rag_chunks{file_suffix}.csv",
            mime="text/csv",
            type="primary",
            use_container_width=True,
        )

    elif export_format == "JSON":
        json_data = json.dumps(export_rows, ensure_ascii=False, indent=2)

        st.download_button(
            label=f"â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ ({len(export_rows)}í–‰)",
            data=json_data,
            file_name=f"rag_chunks{file_suffix}.json",
            mime="application/json",
            type="primary",
            use_container_width=True,
        )

    elif export_format == "SQL (INSERTë¬¸)":
        sql_lines = []
        table_name = "document_chunks"
        for row in export_rows:
            cols = list(row.keys())
            vals = []
            for v in row.values():
                if v is None:
                    vals.append("NULL")
                elif isinstance(v, (int, float)):
                    vals.append(str(v))
                else:
                    escaped = str(v).replace("'", "''")
                    vals.append(f"'{escaped}'")
            sql_lines.append(
                f"INSERT INTO {table_name} ({', '.join(cols)}) VALUES ({', '.join(vals)});"
            )
        sql_data = "\n".join(sql_lines)

        st.download_button(
            label=f"â¬‡ï¸ SQL ë‹¤ìš´ë¡œë“œ ({len(export_rows)}í–‰)",
            data=sql_data,
            file_name=f"rag_chunks{file_suffix}.sql",
            mime="text/plain",
            type="primary",
            use_container_width=True,
        )

    # --- ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë„ ë³„ë„ ë‹¤ìš´ë¡œë“œ ---
    st.divider()
    with st.expander("ğŸ“„ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë„ ë‹¤ìš´ë¡œë“œ"):
        doc_data = db.export_documents()
        doc_json = json.dumps(doc_data, ensure_ascii=False, indent=2)
        st.download_button(
            label=f"â¬‡ï¸ ë¬¸ì„œ ëª©ë¡ JSON ({len(doc_data)}ê°œ)",
            data=doc_json,
            file_name="documents_metadata.json",
            mime="application/json",
            use_container_width=True,
        )

    # --- MySQL ê°€ì´ë“œ ---
    st.divider()
    with st.expander("ğŸ¬ MySQLì— ë„£ëŠ” ë°©ë²• ì•ˆë‚´"):
        st.markdown("""
**1. MySQL í…Œì´ë¸” ìƒì„±**

```sql
CREATE TABLE document_chunks (
    chunk_id BIGINT PRIMARY KEY,
    document_id BIGINT,
    chunk_index INT,
    content LONGTEXT,
    filename VARCHAR(255),
    file_type VARCHAR(50),
    page_number INT,
    created_at DATETIME,
    embedding JSON  -- ë²¡í„° í¬í•¨ ì‹œ
);
```

**2. CSVë¡œ ê°€ì ¸ì˜¤ê¸°**

```sql
LOAD DATA INFILE '/path/to/rag_chunks.csv'
INTO TABLE document_chunks
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\\n'
IGNORE 1 ROWS;
```

**3. ë˜ëŠ” SQL INSERTë¬¸ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰**

```bash
mysql -u root -p database_name < rag_chunks.sql
```
""")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€: ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def page_settings():
    st.header("âš™ï¸ ì„¤ì • í™•ì¸")
    st.caption("í”„ë¡œì íŠ¸ ì„¤ì • ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤")

    errors = check_config()

    if errors:
        st.error("âŒ ì•„ë˜ ì„¤ì •ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”:")
        for err in errors:
            st.markdown(f"- {err}")

        st.divider()
        st.subheader("ğŸ“ ì„¤ì • ë°©ë²•")
        st.markdown(
            "1. í”„ë¡œì íŠ¸ í´ë”ì˜ `.env.example` íŒŒì¼ì„ `.env`ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤\n"
            "2. `.env` íŒŒì¼ì„ ì—´ì–´ ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤\n"
            "3. ì´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤"
        )

        with st.expander("ğŸ“„ .env íŒŒì¼ ì˜ˆì‹œ"):
            st.code(
                "OPENAI_API_KEY=sk-ì‹¤ì œAPIí‚¤\n"
                "SUPABASE_URL=https://í”„ë¡œì íŠ¸.supabase.co\n"
                "SUPABASE_KEY=ì‹¤ì œanoní‚¤\n",
                language="bash",
            )
    else:
        st.success("âœ… ëª¨ë“  ì„¤ì •ì´ ì •ìƒì…ë‹ˆë‹¤!")

    st.divider()
    st.subheader("í˜„ì¬ ì„¤ì •ê°’")

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì„ë² ë”© ëª¨ë¸", Config.EMBEDDING_MODEL)
        st.metric("ì„ë² ë”© ì°¨ì›", Config.EMBEDDING_DIMENSION)
        st.metric("ì±—ë´‡ ëª¨ë¸", Config.CHAT_MODEL)
    with col2:
        st.metric("ì²­í¬ í¬ê¸°", f"{Config.CHUNK_SIZE}ì")
        st.metric("ì²­í¬ ê²¹ì¹¨", f"{Config.CHUNK_OVERLAP}ì")
        supabase_display = Config.SUPABASE_URL[:35] + "..." if Config.SUPABASE_URL else "ë¯¸ì„¤ì •"
        st.metric("Supabase URL", supabase_display)

    st.divider()
    st.subheader("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ")
    st.markdown(
        "`database/schema.sql` íŒŒì¼ì„ Supabase SQL Editorì—ì„œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.  \n"
        "ì´ SQLì€ ë¬¸ì„œ í…Œì´ë¸”, ì²­í¬ í…Œì´ë¸”, ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    if st.button("ğŸ“‹ schema.sql ë‚´ìš© ë³´ê¸°"):
        try:
            schema_path = os.path.join(os.path.dirname(__file__), "database", "schema.sql")
            with open(schema_path, "r", encoding="utf-8") as f:
                st.code(f.read(), language="sql")
        except FileNotFoundError:
            st.error("schema.sql íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¼ìš°íŒ…: ì„ íƒëœ í˜ì´ì§€ ë Œë”ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "ğŸ’¬ ì±—ë´‡":
    page_chat()
elif page == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    page_upload()
elif page == "ğŸ“‹ ë¬¸ì„œ ê´€ë¦¬":
    page_documents()
elif page == "ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°":
    page_export()
elif page == "âš™ï¸ ì„¤ì •":
    page_settings()
